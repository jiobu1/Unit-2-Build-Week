{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Outline***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is a compilation state expenditure, student demographic, and 4th and 8th grade math and reading scores. This project is trying to create a model that can predict student scores based on these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Upload Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "Warning: 4 possible package resolutions (only showing differing packages):\n",
      "  - anaconda/osx-64::ca-certificates-2020.1.1-0, anaconda/osx-64::openssl-1.1.1d-h1de35cc_4\n",
      "  - anaconda/osx-64::ca-certificates-2020.1.1-0, defaults/osx-64::openssl-1.1.1d-h1de35cc_4\n",
      "  - anaconda/osx-64::openssl-1.1.1d-h1de35cc_4, defaults/osx-64::ca-certificates-2020.1.1-0\n",
      "  - defaults/osx-64::ca-certificates-2020.1.1-0, defaults/osx-64::openssl-1.1.1d-h1de35ccdone\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/jisha/Unit 240_Build_Week/data/'\n",
    "states = pd.read_csv(DATA_PATH + 'states_all_extended.csv')\n",
    "finances = pd.read_csv(DATA_PATH + 'finance_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_TRF</th>\n",
       "      <th>GRADES_8_TRF</th>\n",
       "      <th>GRADES_12_TRF</th>\n",
       "      <th>GRADES_1_8_TRF</th>\n",
       "      <th>GRADES_9_12_TRF</th>\n",
       "      <th>GRADES_ALL_TRF</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>252.187522</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.859712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>265.366278</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262.169895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>256.312090</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264.619665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>260.892247</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_TRF  GRADES_8_TRF  GRADES_12_TRF  GRADES_1_8_TRF  \\\n",
       "0  ...           NaN           NaN            NaN             NaN   \n",
       "1  ...           NaN           NaN            NaN             NaN   \n",
       "2  ...           NaN           NaN            NaN             NaN   \n",
       "3  ...           NaN           NaN            NaN             NaN   \n",
       "4  ...           NaN           NaN            NaN             NaN   \n",
       "\n",
       "   GRADES_9_12_TRF  GRADES_ALL_TRF  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0              NaN             NaN        208.327876        252.187522   \n",
       "1              NaN             NaN               NaN               NaN   \n",
       "2              NaN             NaN        215.253932        265.366278   \n",
       "3              NaN             NaN        210.206028        256.312090   \n",
       "4              NaN             NaN        208.398961        260.892247   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0           207.963517                  NaN  \n",
       "1                  NaN           258.859712  \n",
       "2           206.212716           262.169895  \n",
       "3           208.634458           264.619665  \n",
       "4           196.764414                  NaN  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885</td>\n",
       "      <td>304177</td>\n",
       "      <td>1659028</td>\n",
       "      <td>715680</td>\n",
       "      <td>2653798</td>\n",
       "      <td>1481703</td>\n",
       "      <td>735036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591</td>\n",
       "      <td>106780</td>\n",
       "      <td>720711</td>\n",
       "      <td>222100</td>\n",
       "      <td>972488</td>\n",
       "      <td>498362</td>\n",
       "      <td>350902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079</td>\n",
       "      <td>297888</td>\n",
       "      <td>1369815</td>\n",
       "      <td>1590376</td>\n",
       "      <td>3401580</td>\n",
       "      <td>1435908</td>\n",
       "      <td>1007732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959</td>\n",
       "      <td>178571</td>\n",
       "      <td>958785</td>\n",
       "      <td>574603</td>\n",
       "      <td>1743022</td>\n",
       "      <td>964323</td>\n",
       "      <td>483488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025</td>\n",
       "      <td>2072470</td>\n",
       "      <td>16546514</td>\n",
       "      <td>7641041</td>\n",
       "      <td>27138832</td>\n",
       "      <td>14358922</td>\n",
       "      <td>8520926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2044688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN        2678885           304177   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN        1049591           106780   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN        3258079           297888   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN        1711959           178571   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN       26260025          2072470   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0        1659028         715680            2653798                  1481703   \n",
       "1         720711         222100             972488                   498362   \n",
       "2        1369815        1590376            3401580                  1435908   \n",
       "3         958785         574603            1743022                   964323   \n",
       "4       16546514        7641041           27138832                 14358922   \n",
       "\n",
       "   SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  CAPITAL_OUTLAY_EXPENDITURE  \n",
       "0                        735036                NaN                      174053  \n",
       "1                        350902                NaN                       37451  \n",
       "2                       1007732                NaN                      609114  \n",
       "3                        483488                NaN                      145212  \n",
       "4                       8520926                NaN                     2044688  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1492, 193), (1326, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape, finances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Update Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Merging Tail***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merging the tail of both dataframes before concating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_tail = pd.DataFrame(states.tail(51))\n",
    "finance_tail = pd.DataFrame(finances.tail(51)) #I just need the last 51 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51, 193), (51, 13))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tail.shape, finance_tail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ENROLL','TOTAL_REVENUE','FEDERAL_REVENUE',\n",
    "           'STATE_REVENUE','LOCAL_REVENUE','TOTAL_EXPENDITURE',\n",
    "           'INSTRUCTION_EXPENDITURE','SUPPORT_SERVICES_EXPENDITURE',\n",
    "           'OTHER_EXPENDITURE','CAPITAL_OUTLAY_EXPENDITURE']\n",
    "state_tail = state_tail.drop(columns=columns) #Dropping unnecessary columns from state_tail, so I do not have to do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(finance_tail, state_tail, on=['PRIMARY_KEY','STATE', 'YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 193)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_TRF</th>\n",
       "      <th>GRADES_8_TRF</th>\n",
       "      <th>GRADES_12_TRF</th>\n",
       "      <th>GRADES_1_8_TRF</th>\n",
       "      <th>GRADES_9_12_TRF</th>\n",
       "      <th>GRADES_ALL_TRF</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2017</td>\n",
       "      <td>744930.0</td>\n",
       "      <td>7911674</td>\n",
       "      <td>811407</td>\n",
       "      <td>4350594</td>\n",
       "      <td>2749673</td>\n",
       "      <td>8031412</td>\n",
       "      <td>4046379</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.170688</td>\n",
       "      <td>268.312020</td>\n",
       "      <td>216.419814</td>\n",
       "      <td>257.686520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2017</td>\n",
       "      <td>132737.0</td>\n",
       "      <td>2504501</td>\n",
       "      <td>350204</td>\n",
       "      <td>1600503</td>\n",
       "      <td>553794</td>\n",
       "      <td>2587060</td>\n",
       "      <td>1266077</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.456278</td>\n",
       "      <td>277.015572</td>\n",
       "      <td>207.037630</td>\n",
       "      <td>257.667497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2017</td>\n",
       "      <td>936147.0</td>\n",
       "      <td>8677631</td>\n",
       "      <td>1178196</td>\n",
       "      <td>3446191</td>\n",
       "      <td>4053244</td>\n",
       "      <td>8389808</td>\n",
       "      <td>4081153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.435788</td>\n",
       "      <td>282.248145</td>\n",
       "      <td>215.465952</td>\n",
       "      <td>262.957457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2017</td>\n",
       "      <td>478996.0</td>\n",
       "      <td>5481422</td>\n",
       "      <td>597260</td>\n",
       "      <td>4137903</td>\n",
       "      <td>746259</td>\n",
       "      <td>5479899</td>\n",
       "      <td>2691959</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.848144</td>\n",
       "      <td>273.759907</td>\n",
       "      <td>216.108026</td>\n",
       "      <td>259.955798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>6195344.0</td>\n",
       "      <td>91803968</td>\n",
       "      <td>7889546</td>\n",
       "      <td>51046506</td>\n",
       "      <td>32867916</td>\n",
       "      <td>90161939</td>\n",
       "      <td>44748095</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.262941</td>\n",
       "      <td>276.638200</td>\n",
       "      <td>215.421814</td>\n",
       "      <td>262.520630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR     ENROLL  TOTAL_REVENUE  \\\n",
       "0     2017_ALABAMA     ALABAMA  2017   744930.0        7911674   \n",
       "1      2017_ALASKA      ALASKA  2017   132737.0        2504501   \n",
       "2     2017_ARIZONA     ARIZONA  2017   936147.0        8677631   \n",
       "3    2017_ARKANSAS    ARKANSAS  2017   478996.0        5481422   \n",
       "4  2017_CALIFORNIA  CALIFORNIA  2017  6195344.0       91803968   \n",
       "\n",
       "   FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "0           811407        4350594        2749673            8031412   \n",
       "1           350204        1600503         553794            2587060   \n",
       "2          1178196        3446191        4053244            8389808   \n",
       "3           597260        4137903         746259            5479899   \n",
       "4          7889546       51046506       32867916           90161939   \n",
       "\n",
       "   INSTRUCTION_EXPENDITURE  ...  GRADES_4_TRF  GRADES_8_TRF  GRADES_12_TRF  \\\n",
       "0                  4046379  ...           NaN           NaN            NaN   \n",
       "1                  1266077  ...           NaN           NaN            NaN   \n",
       "2                  4081153  ...           NaN           NaN            NaN   \n",
       "3                  2691959  ...           NaN           NaN            NaN   \n",
       "4                 44748095  ...           NaN           NaN            NaN   \n",
       "\n",
       "   GRADES_1_8_TRF  GRADES_9_12_TRF  GRADES_ALL_TRF  AVG_MATH_4_SCORE  \\\n",
       "0             NaN              NaN             NaN        232.170688   \n",
       "1             NaN              NaN             NaN        230.456278   \n",
       "2             NaN              NaN             NaN        234.435788   \n",
       "3             NaN              NaN             NaN        233.848144   \n",
       "4             NaN              NaN             NaN        232.262941   \n",
       "\n",
       "   AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0        268.312020           216.419814           257.686520  \n",
       "1        277.015572           207.037630           257.667497  \n",
       "2        282.248145           215.465952           262.957457  \n",
       "3        273.759907           216.108026           259.955798  \n",
       "4        276.638200           215.421814           262.520630  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Concatenating Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = states.head(1441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = head.append(merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Choose your evaluation metric(s)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>252.187522</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.859712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>265.366278</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262.169895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>256.312090</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264.619665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>260.892247</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0     1992_ALABAMA     ALABAMA        208.327876        252.187522   \n",
       "1      1992_ALASKA      ALASKA               NaN               NaN   \n",
       "2     1992_ARIZONA     ARIZONA        215.253932        265.366278   \n",
       "3    1992_ARKANSAS    ARKANSAS        210.206028        256.312090   \n",
       "4  1992_CALIFORNIA  CALIFORNIA        208.398961        260.892247   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0           207.963517                  NaN  \n",
       "1                  NaN           258.859712  \n",
       "2           206.212716           262.169895  \n",
       "3           208.634458           264.619665  \n",
       "4           196.764414                  NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = df[['PRIMARY_KEY','STATE','AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE', 'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE' ]].copy()\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 8th grade reading. Creating a classification class by grouping the scores into different categories. I think this will give more information then the numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticings: Unfortunately, the state scores are not very good for any of the states for any of the years. Most states, across both Math and Reading, have underperformed; only a small percentage scored proficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8th Grade Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Cleaning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code finds the mean by states and then fills in NaN values with that mean\n",
    "target_df['AVG_READING_8_SCORE'] = target_df.groupby('STATE')['AVG_READING_8_SCORE'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_READING_8_SCORE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     264\n",
       "1     258\n",
       "2     262\n",
       "3     264\n",
       "4     261\n",
       "     ... \n",
       "46    273\n",
       "47    267\n",
       "48    271\n",
       "49    258\n",
       "50    269\n",
       "Name: AVG_READING_8_SCORE, Length: 1492, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_READING_8_SCORE'] = target_df['AVG_READING_8_SCORE'].fillna(0)\n",
    "target_df['AVG_READING_8_SCORE'] = target_df['AVG_READING_8_SCORE'].astype(int)\n",
    "target_df['AVG_READING_8_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264    218\n",
       "263    191\n",
       "265    163\n",
       "0      161\n",
       "262    134\n",
       "261    117\n",
       "266    105\n",
       "260     70\n",
       "267     47\n",
       "259     35\n",
       "268     34\n",
       "269     32\n",
       "270     21\n",
       "257     19\n",
       "258     18\n",
       "272     14\n",
       "251     13\n",
       "255     12\n",
       "253     11\n",
       "254     10\n",
       "273      9\n",
       "271      9\n",
       "256      8\n",
       "274      7\n",
       "252      7\n",
       "250      6\n",
       "277      3\n",
       "275      3\n",
       "276      2\n",
       "247      2\n",
       "238      2\n",
       "242      2\n",
       "239      1\n",
       "236      1\n",
       "249      1\n",
       "240      1\n",
       "246      1\n",
       "248      1\n",
       "280      1\n",
       "Name: AVG_READING_8_SCORE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_READING_8_SCORE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 280)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(target_df['AVG_READING_8_SCORE']), max(target_df['AVG_READING_8_SCORE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAEP Reading Score Breakdown\n",
    "- basic (0-280)\n",
    "> This column was broken down into 3 categories: \n",
    "> - low, \n",
    "> - mid, and \n",
    "> - high basic\n",
    "- proficient (281-322)\n",
    "- advanced (323-500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     2\n",
       "2     2\n",
       "3     2\n",
       "4     2\n",
       "     ..\n",
       "46    3\n",
       "47    3\n",
       "48    3\n",
       "49    2\n",
       "50    3\n",
       "Name: READING_PROF_8, Length: 1492, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def proficiency(row):\n",
    "  #separating basic into 3 groups (0-281)\n",
    "    if 0< row['AVG_READING_8_SCORE'] < 240:\n",
    "        val = '1'\n",
    "    elif 240 <= row['AVG_READING_8_SCORE'] < 265:\n",
    "        val = '2'\n",
    "    elif 265 <= row['AVG_READING_8_SCORE'] < 281:\n",
    "        val = '3'\n",
    "    elif 281 <= row['AVG_READING_8_SCORE'] < 323:\n",
    "        val = '4'\n",
    "    elif row['AVG_READING_8_SCORE'] >= 323:\n",
    "        val = '5'\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "target_df['READING_PROF_8'] = target_df.apply(proficiency, axis=1)\n",
    "target_df['READING_PROF_8'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.587802\n",
       "3    0.301609\n",
       "0    0.107909\n",
       "1    0.002681\n",
       "Name: READING_PROF_8, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['READING_PROF_8'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8th Grade Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Cleaning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code finds the mean by states and then fills in NaN values with that mean\n",
    "target_df['AVG_MATH_8_SCORE'] = target_df.groupby('STATE')['AVG_MATH_8_SCORE'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_MATH_8_SCORE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     252\n",
       "1     280\n",
       "2     265\n",
       "3     256\n",
       "4     260\n",
       "     ... \n",
       "46    290\n",
       "47    289\n",
       "48    273\n",
       "49    288\n",
       "50    288\n",
       "Name: AVG_MATH_8_SCORE, Length: 1492, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_MATH_8_SCORE'] = target_df['AVG_MATH_8_SCORE'].fillna(0)\n",
    "target_df['AVG_MATH_8_SCORE'] = target_df['AVG_MATH_8_SCORE'].astype(int)\n",
    "target_df['AVG_MATH_8_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      161\n",
       "283    115\n",
       "282    101\n",
       "280     72\n",
       "287     68\n",
       "273     60\n",
       "277     57\n",
       "288     55\n",
       "285     54\n",
       "284     54\n",
       "279     49\n",
       "275     47\n",
       "286     47\n",
       "274     46\n",
       "278     46\n",
       "270     45\n",
       "281     44\n",
       "269     40\n",
       "271     28\n",
       "289     27\n",
       "272     25\n",
       "262     25\n",
       "290     24\n",
       "266     24\n",
       "265     23\n",
       "291     23\n",
       "263     21\n",
       "250     18\n",
       "276     13\n",
       "268     11\n",
       "267      7\n",
       "292      6\n",
       "294      6\n",
       "259      5\n",
       "260      5\n",
       "264      4\n",
       "261      4\n",
       "293      4\n",
       "258      3\n",
       "256      2\n",
       "234      2\n",
       "252      2\n",
       "297      2\n",
       "253      2\n",
       "295      2\n",
       "298      2\n",
       "296      2\n",
       "254      1\n",
       "257      1\n",
       "249      1\n",
       "248      1\n",
       "246      1\n",
       "245      1\n",
       "243      1\n",
       "232      1\n",
       "300      1\n",
       "Name: AVG_MATH_8_SCORE, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['AVG_MATH_8_SCORE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(target_df['AVG_MATH_8_SCORE']), max(target_df['AVG_MATH_8_SCORE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAEP Math Score Breakdown\n",
    "- basic (0-298)\n",
    "> This column was broken down into 3 categories:\n",
    "> -  low, \n",
    "> - mid, and \n",
    "> - high basic\n",
    "- proficient (298-332)\n",
    "- advanced (333-500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "46    3\n",
       "47    3\n",
       "48    2\n",
       "49    3\n",
       "50    3\n",
       "Name: MATH_PROF_8, Length: 1492, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def proficiency(row):\n",
    "    if 0 < row['AVG_MATH_8_SCORE'] < 270:\n",
    "        val = '1'\n",
    "    elif 270 <= row['AVG_MATH_8_SCORE'] < 280:\n",
    "        val = '2 '\n",
    "    elif 280 <= row['AVG_MATH_8_SCORE'] < 299:\n",
    "        val = '3'    \n",
    "    elif 299 <= row['AVG_MATH_8_SCORE'] < 333:\n",
    "        val = '4'\n",
    "    elif row['AVG_MATH_8_SCORE'] >= 333:\n",
    "        val = '5'\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "target_df['MATH_PROF_8'] = target_df.apply(proficiency, axis=1)\n",
    "target_df['MATH_PROF_8'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.474531\n",
       "2     0.278820\n",
       "1     0.138070\n",
       "0     0.107909\n",
       "4     0.000670\n",
       "Name: MATH_PROF_8, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['MATH_PROF_8'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Target***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the two new engineered features back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['AVG_READING_8_SCORE', 'AVG_MATH_8_SCORE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_12_TRF</th>\n",
       "      <th>GRADES_1_8_TRF</th>\n",
       "      <th>GRADES_9_12_TRF</th>\n",
       "      <th>GRADES_ALL_TRF</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>READING_PROF_8</th>\n",
       "      <th>MATH_PROF_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>264</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>261</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_12_TRF  GRADES_1_8_TRF  GRADES_9_12_TRF  GRADES_ALL_TRF  \\\n",
       "0  ...            NaN             NaN              NaN             NaN   \n",
       "1  ...            NaN             NaN              NaN             NaN   \n",
       "2  ...            NaN             NaN              NaN             NaN   \n",
       "3  ...            NaN             NaN              NaN             NaN   \n",
       "4  ...            NaN             NaN              NaN             NaN   \n",
       "\n",
       "   AVG_MATH_4_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \\\n",
       "0        208.327876           207.963517                  264   \n",
       "1               NaN                  NaN                  258   \n",
       "2        215.253932           206.212716                  262   \n",
       "3        210.206028           208.634458                  264   \n",
       "4        208.398961           196.764414                  261   \n",
       "\n",
       "   AVG_MATH_8_SCORE  READING_PROF_8  MATH_PROF_8  \n",
       "0               252               2            1  \n",
       "1               280               2            3  \n",
       "2               265               2            1  \n",
       "3               256               2            1  \n",
       "4               260               2            1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['AVG_READING_8_SCORE', 'AVG_MATH_8_SCORE','READING_PROF_8', 'MATH_PROF_8']] = target_df[['AVG_READING_8_SCORE', 'AVG_MATH_8_SCORE','READING_PROF_8','MATH_PROF_8' ]].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['READING_PROF_8'] = df['READING_PROF_8'].astype(int)\n",
    "df['MATH_PROF_8'] = df['MATH_PROF_8'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY             object\n",
       "STATE                   object\n",
       "YEAR                     int64\n",
       "ENROLL                 float64\n",
       "TOTAL_REVENUE          float64\n",
       "                        ...   \n",
       "AVG_READING_4_SCORE    float64\n",
       "AVG_READING_8_SCORE      int64\n",
       "AVG_MATH_8_SCORE         int64\n",
       "READING_PROF_8           int64\n",
       "MATH_PROF_8              int64\n",
       "Length: 195, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Train/Val/Test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1277, 195), (215, 195))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['YEAR'] <= 2013]\n",
    "test = df[df['YEAR'] > 2013]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((766, 195), (511, 195), (215, 195))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(\n",
    "    train, train_size=0.60, test_size=0.40,\n",
    "    stratify=train['READING_PROF_8'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Cleaning Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- There are several columns that do not have any data. \n",
    "\n",
    "**DROP**\n",
    "- primary key (this is just a combination of state and year\n",
    "- Since this model is trying to predict scores for each state, I will be dropping the years that do not have any recorded scores. \n",
    "- This data contains information for all 50 states, including Washington D.C, as well as US territories. Unfortunately, there is not information about expenditure for those columns, so that information will be dropped as well. \n",
    "- I will create a new dataframe which has the breakdown of demographics and then delete those columns from this dataframe. The demographics info was not captured until 2009, that will be too many np.nan values to use to build a useful model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRIMARY_KEY', 'STATE', 'YEAR', 'ENROLL', 'TOTAL_REVENUE',\n",
       "       'FEDERAL_REVENUE', 'STATE_REVENUE', 'LOCAL_REVENUE',\n",
       "       'TOTAL_EXPENDITURE', 'INSTRUCTION_EXPENDITURE',\n",
       "       ...\n",
       "       'GRADES_12_TRF', 'GRADES_1_8_TRF', 'GRADES_9_12_TRF', 'GRADES_ALL_TRF',\n",
       "       'AVG_MATH_4_SCORE', 'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE',\n",
       "       'AVG_MATH_8_SCORE', 'READING_PROF_8', 'MATH_PROF_8'],\n",
       "      dtype='object', length=195)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Feature Engineering***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this dataset, I would delete the years where the NAEP test scores are not available since that does not give anything for me to train/validate/test the data on. The data is from 1992 - 2017. The NAEP only gives information for the years 1992, 1996, 2000, 2003, 2005, 2007, 2009, 2011, 2013, 2015, 2017. ✓\n",
    "- I will also delete the years where I do not have the finacial information available ✓\n",
    "- I am using information from the consumer price index to create new columns that adjust revenue and expenditures to reflect inflation ✓\n",
    "https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/\n",
    " * https://www.usinflationcalculator.com/frequently-asked-questions-faqs/#HowInflationCalculatorWorks\n",
    "- look at %of total revenue spent on education✓\n",
    "- look at % of total expenditure spent on instruction, support other, and capital outlay✓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Averages\n",
    "* replacing nulls with state averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_12_TRF</th>\n",
       "      <th>GRADES_1_8_TRF</th>\n",
       "      <th>GRADES_9_12_TRF</th>\n",
       "      <th>GRADES_ALL_TRF</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>READING_PROF_8</th>\n",
       "      <th>MATH_PROF_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALABAMA</th>\n",
       "      <td>2002.900000</td>\n",
       "      <td>733965.900000</td>\n",
       "      <td>5.500469e+06</td>\n",
       "      <td>568936.200000</td>\n",
       "      <td>3.194067e+06</td>\n",
       "      <td>1.737466e+06</td>\n",
       "      <td>5.624908e+06</td>\n",
       "      <td>2.914756e+06</td>\n",
       "      <td>1.620027e+06</td>\n",
       "      <td>451126.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.645299</td>\n",
       "      <td>210.408278</td>\n",
       "      <td>264.700000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALASKA</th>\n",
       "      <td>2004.333333</td>\n",
       "      <td>130848.733333</td>\n",
       "      <td>1.691878e+06</td>\n",
       "      <td>265068.933333</td>\n",
       "      <td>1.021510e+06</td>\n",
       "      <td>4.052985e+05</td>\n",
       "      <td>1.819245e+06</td>\n",
       "      <td>8.951511e+05</td>\n",
       "      <td>6.266891e+05</td>\n",
       "      <td>58791.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>263.20</td>\n",
       "      <td>3073.800000</td>\n",
       "      <td>1166.2</td>\n",
       "      <td>4334.200000</td>\n",
       "      <td>234.186236</td>\n",
       "      <td>210.913963</td>\n",
       "      <td>263.800000</td>\n",
       "      <td>280.200000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMERICAN_SAMOA</th>\n",
       "      <td>2002.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIZONA</th>\n",
       "      <td>2003.176471</td>\n",
       "      <td>875459.062500</td>\n",
       "      <td>6.549546e+06</td>\n",
       "      <td>783975.470588</td>\n",
       "      <td>2.760691e+06</td>\n",
       "      <td>3.004879e+06</td>\n",
       "      <td>6.605608e+06</td>\n",
       "      <td>3.032112e+06</td>\n",
       "      <td>2.051728e+06</td>\n",
       "      <td>323763.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>480.75</td>\n",
       "      <td>5919.250000</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>8251.250000</td>\n",
       "      <td>227.348464</td>\n",
       "      <td>208.783949</td>\n",
       "      <td>263.176471</td>\n",
       "      <td>274.176471</td>\n",
       "      <td>2.176471</td>\n",
       "      <td>1.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARKANSAS</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>437997.083333</td>\n",
       "      <td>3.259555e+06</td>\n",
       "      <td>371155.769231</td>\n",
       "      <td>2.305379e+06</td>\n",
       "      <td>5.830208e+05</td>\n",
       "      <td>3.387348e+06</td>\n",
       "      <td>1.724709e+06</td>\n",
       "      <td>1.005450e+06</td>\n",
       "      <td>254008.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>879.5</td>\n",
       "      <td>3341.750000</td>\n",
       "      <td>226.369523</td>\n",
       "      <td>213.676209</td>\n",
       "      <td>264.538462</td>\n",
       "      <td>268.692308</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>1.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIRGIN_ISLANDS</th>\n",
       "      <td>2003.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.00</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>44.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASHINGTON</th>\n",
       "      <td>2001.866667</td>\n",
       "      <td>995417.000000</td>\n",
       "      <td>8.413861e+06</td>\n",
       "      <td>657610.466667</td>\n",
       "      <td>5.289223e+06</td>\n",
       "      <td>2.467028e+06</td>\n",
       "      <td>8.648341e+06</td>\n",
       "      <td>4.227706e+06</td>\n",
       "      <td>2.509973e+06</td>\n",
       "      <td>377268.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>1753.00</td>\n",
       "      <td>17804.000000</td>\n",
       "      <td>7526.5</td>\n",
       "      <td>25543.500000</td>\n",
       "      <td>240.417536</td>\n",
       "      <td>222.917322</td>\n",
       "      <td>264.933333</td>\n",
       "      <td>284.666667</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEST_VIRGINIA</th>\n",
       "      <td>2002.666667</td>\n",
       "      <td>293047.888889</td>\n",
       "      <td>2.608390e+06</td>\n",
       "      <td>262479.777778</td>\n",
       "      <td>1.534276e+06</td>\n",
       "      <td>8.116347e+05</td>\n",
       "      <td>2.557555e+06</td>\n",
       "      <td>1.413668e+06</td>\n",
       "      <td>7.827014e+05</td>\n",
       "      <td>167582.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1566.500000</td>\n",
       "      <td>278.0</td>\n",
       "      <td>2077.000000</td>\n",
       "      <td>229.120583</td>\n",
       "      <td>216.162878</td>\n",
       "      <td>265.888889</td>\n",
       "      <td>269.111111</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WISCONSIN</th>\n",
       "      <td>2003.916667</td>\n",
       "      <td>864421.000000</td>\n",
       "      <td>9.007533e+06</td>\n",
       "      <td>611281.333333</td>\n",
       "      <td>4.348686e+06</td>\n",
       "      <td>4.047566e+06</td>\n",
       "      <td>9.001521e+06</td>\n",
       "      <td>4.814670e+06</td>\n",
       "      <td>2.765744e+06</td>\n",
       "      <td>359151.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>446.00</td>\n",
       "      <td>5275.333333</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>8002.666667</td>\n",
       "      <td>243.260335</td>\n",
       "      <td>221.358970</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>285.416667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WYOMING</th>\n",
       "      <td>2003.400000</td>\n",
       "      <td>90548.500000</td>\n",
       "      <td>1.110215e+06</td>\n",
       "      <td>87845.400000</td>\n",
       "      <td>5.625480e+05</td>\n",
       "      <td>4.598213e+05</td>\n",
       "      <td>1.080726e+06</td>\n",
       "      <td>5.424888e+05</td>\n",
       "      <td>3.357150e+05</td>\n",
       "      <td>33150.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.00</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>232.140852</td>\n",
       "      <td>220.542973</td>\n",
       "      <td>261.600000</td>\n",
       "      <td>282.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       YEAR         ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "STATE                                                                        \n",
       "ALABAMA         2002.900000  733965.900000   5.500469e+06    568936.200000   \n",
       "ALASKA          2004.333333  130848.733333   1.691878e+06    265068.933333   \n",
       "AMERICAN_SAMOA  2002.700000            NaN            NaN              NaN   \n",
       "ARIZONA         2003.176471  875459.062500   6.549546e+06    783975.470588   \n",
       "ARKANSAS        2002.000000  437997.083333   3.259555e+06    371155.769231   \n",
       "...                     ...            ...            ...              ...   \n",
       "VIRGIN_ISLANDS  2003.083333            NaN            NaN              NaN   \n",
       "WASHINGTON      2001.866667  995417.000000   8.413861e+06    657610.466667   \n",
       "WEST_VIRGINIA   2002.666667  293047.888889   2.608390e+06    262479.777778   \n",
       "WISCONSIN       2003.916667  864421.000000   9.007533e+06    611281.333333   \n",
       "WYOMING         2003.400000   90548.500000   1.110215e+06     87845.400000   \n",
       "\n",
       "                STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "STATE                                                             \n",
       "ALABAMA          3.194067e+06   1.737466e+06       5.624908e+06   \n",
       "ALASKA           1.021510e+06   4.052985e+05       1.819245e+06   \n",
       "AMERICAN_SAMOA            NaN            NaN                NaN   \n",
       "ARIZONA          2.760691e+06   3.004879e+06       6.605608e+06   \n",
       "ARKANSAS         2.305379e+06   5.830208e+05       3.387348e+06   \n",
       "...                       ...            ...                ...   \n",
       "VIRGIN_ISLANDS            NaN            NaN                NaN   \n",
       "WASHINGTON       5.289223e+06   2.467028e+06       8.648341e+06   \n",
       "WEST_VIRGINIA    1.534276e+06   8.116347e+05       2.557555e+06   \n",
       "WISCONSIN        4.348686e+06   4.047566e+06       9.001521e+06   \n",
       "WYOMING          5.625480e+05   4.598213e+05       1.080726e+06   \n",
       "\n",
       "                INSTRUCTION_EXPENDITURE  SUPPORT_SERVICES_EXPENDITURE  \\\n",
       "STATE                                                                   \n",
       "ALABAMA                    2.914756e+06                  1.620027e+06   \n",
       "ALASKA                     8.951511e+05                  6.266891e+05   \n",
       "AMERICAN_SAMOA                      NaN                           NaN   \n",
       "ARIZONA                    3.032112e+06                  2.051728e+06   \n",
       "ARKANSAS                   1.724709e+06                  1.005450e+06   \n",
       "...                                 ...                           ...   \n",
       "VIRGIN_ISLANDS                      NaN                           NaN   \n",
       "WASHINGTON                 4.227706e+06                  2.509973e+06   \n",
       "WEST_VIRGINIA              1.413668e+06                  7.827014e+05   \n",
       "WISCONSIN                  4.814670e+06                  2.765744e+06   \n",
       "WYOMING                    5.424888e+05                  3.357150e+05   \n",
       "\n",
       "                OTHER_EXPENDITURE  ...  GRADES_12_TRF  GRADES_1_8_TRF  \\\n",
       "STATE                              ...                                  \n",
       "ALABAMA             451126.900000  ...            NaN             NaN   \n",
       "ALASKA               58791.533333  ...         263.20     3073.800000   \n",
       "AMERICAN_SAMOA                NaN  ...            NaN             NaN   \n",
       "ARIZONA             323763.562500  ...         480.75     5919.250000   \n",
       "ARKANSAS            254008.833333  ...         188.00     2359.000000   \n",
       "...                           ...  ...            ...             ...   \n",
       "VIRGIN_ISLANDS                NaN  ...          11.00       33.000000   \n",
       "WASHINGTON          377268.466667  ...        1753.00    17804.000000   \n",
       "WEST_VIRGINIA       167582.555556  ...          55.50     1566.500000   \n",
       "WISCONSIN           359151.333333  ...         446.00     5275.333333   \n",
       "WYOMING              33150.300000  ...          38.00      405.000000   \n",
       "\n",
       "                GRADES_9_12_TRF  GRADES_ALL_TRF  AVG_MATH_4_SCORE  \\\n",
       "STATE                                                               \n",
       "ALABAMA                     NaN             NaN        225.645299   \n",
       "ALASKA                   1166.2     4334.200000        234.186236   \n",
       "AMERICAN_SAMOA              NaN             NaN               NaN   \n",
       "ARIZONA                  2277.0     8251.250000        227.348464   \n",
       "ARKANSAS                  879.5     3341.750000        226.369523   \n",
       "...                         ...             ...               ...   \n",
       "VIRGIN_ISLANDS             44.5             NaN               NaN   \n",
       "WASHINGTON               7526.5    25543.500000        240.417536   \n",
       "WEST_VIRGINIA             278.0     2077.000000        229.120583   \n",
       "WISCONSIN                1967.0     8002.666667        243.260335   \n",
       "WYOMING                   183.0      594.000000        232.140852   \n",
       "\n",
       "                AVG_READING_4_SCORE  AVG_READING_8_SCORE  AVG_MATH_8_SCORE  \\\n",
       "STATE                                                                        \n",
       "ALABAMA                  210.408278           264.700000        263.000000   \n",
       "ALASKA                   210.913963           263.800000        280.200000   \n",
       "AMERICAN_SAMOA                  NaN             0.000000          0.000000   \n",
       "ARIZONA                  208.783949           263.176471        274.176471   \n",
       "ARKANSAS                 213.676209           264.538462        268.692308   \n",
       "...                             ...                  ...               ...   \n",
       "VIRGIN_ISLANDS                  NaN             0.000000          0.000000   \n",
       "WASHINGTON               222.917322           264.933333        284.666667   \n",
       "WEST_VIRGINIA            216.162878           265.888889        269.111111   \n",
       "WISCONSIN                221.358970           263.000000        285.416667   \n",
       "WYOMING                  220.542973           261.600000        282.100000   \n",
       "\n",
       "                READING_PROF_8  MATH_PROF_8  \n",
       "STATE                                        \n",
       "ALABAMA               2.200000     1.000000  \n",
       "ALASKA                2.333333     2.800000  \n",
       "AMERICAN_SAMOA        0.000000     0.000000  \n",
       "ARIZONA               2.176471     1.882353  \n",
       "ARKANSAS              2.307692     1.769231  \n",
       "...                        ...          ...  \n",
       "VIRGIN_ISLANDS        0.000000     0.000000  \n",
       "WASHINGTON            2.933333     3.000000  \n",
       "WEST_VIRGINIA         2.888889     1.222222  \n",
       "WISCONSIN             2.166667     3.000000  \n",
       "WYOMING               2.000000     2.900000  \n",
       "\n",
       "[75 rows x 193 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('STATE').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjustment for Inflation\n",
    "I am using information from the consumer price index to create new columns that adjust expenditures to reflect inflation ✓\n",
    "* https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/\n",
    "* https://www.usinflationcalculator.com/frequently-asked-questions-faqs/#HowInflationCalculatorWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = {1992: 140.3,\n",
    "       1993: 144.5,\n",
    "       1994: 148.2,\n",
    "       1995: 152.4,\n",
    "       1996: 156.9,\n",
    "       1997: 160.5,\n",
    "       1998: 163.0,\n",
    "       1999: 166.6,\n",
    "       2000: 172.2,\n",
    "       2001: 177.1,\n",
    "       2002: 179.9,\n",
    "       2003: 184.0,\n",
    "       2004: 188.9,\n",
    "       2005: 195.3,\n",
    "       2006: 201.6,\n",
    "       2007: 207.3,\n",
    "       2008: 215.303,\n",
    "       2009: 214.537,\n",
    "       2010: 218.056,\n",
    "       2011: 224.939,\n",
    "       2012: 229.594,\n",
    "       2013: 232.957,\n",
    "       2014: 236.736,\n",
    "       2015: 237.017,\n",
    "       2016: 240.007,\n",
    "       2017: 245.120,\n",
    "       2018: 251.107,\n",
    "       2019: 255.657}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.657\n"
     ]
    }
   ],
   "source": [
    "baseline_year = 2019\n",
    "baseline_inflation = cpi[baseline_year]\n",
    "print(baseline_inflation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflation_adjustment(row, baseline_inflation, src):\n",
    "    return row[src] * (baseline_inflation/ cpi[row['YEAR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Wrangle***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "\n",
    "    X = X.replace (0, np.NaN)\n",
    "\n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    cols_with_zeros = ['AVG_MATH_8_SCORE','AVG_READING_8_SCORE']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "\n",
    "    #Dropping rows if they do not contain any score data, will not drop if there is just 1 value\n",
    "    X = X.dropna(axis=0, subset=['AVG_MATH_4_SCORE', 'AVG_MATH_8_SCORE', 'AVG_READING_4_SCORE', 'AVG_READING_8_SCORE'], how = 'any')\n",
    "\n",
    "    #Dropping rows that do not contain any financial information\n",
    "    X = X.dropna(axis=0, subset = ['TOTAL_REVENUE','FEDERAL_REVENUE','STATE_REVENUE','LOCAL_REVENUE','TOTAL_EXPENDITURE'], how = 'all')\n",
    "\n",
    "    #Dropping columns\n",
    "    #Primary Key is just State and Year\n",
    "    #Dropping breakdown of demographics into male/female because this does not start to get recorded until 2009\n",
    "    drop = ['PRIMARY_KEY',\n",
    "            'GRADES_PK_HP','GRADES_KG_HP','GRADES_4_HP','GRADES_8_HP','GRADES_12_HP', 'GRADES_1_8_HP', 'GRADES_9_12_HP', 'GRADES_ALL_HP',\n",
    "            'GRADES_PK_TR','GRADES_KG_TR','GRADES_4_TR','GRADES_8_TR','GRADES_12_TR', 'GRADES_1_8_TR', 'GRADES_9_12_TR', 'GRADES_ALL_TR',\n",
    "            'GRADES_PK_AMM','GRADES_KG_AMM','GRADES_4_AMM','GRADES_8_AMM','GRADES_12_AMM', 'GRADES_1_8_AMM', 'GRADES_9_12_AMM', 'GRADES_ALL_AMM',\n",
    "            'GRADES_PK_AMF','GRADES_KG_AMF','GRADES_4_AMF','GRADES_8_AMF','GRADES_12_AMF', 'GRADES_1_8_AMF', 'GRADES_9_12_AMF', 'GRADES_ALL_AMF',\n",
    "            'GRADES_PK_ASM','GRADES_KG_ASM','GRADES_4_ASM','GRADES_8_ASM','GRADES_12_ASM', 'GRADES_1_8_ASM', 'GRADES_9_12_ASM', 'GRADES_ALL_ASM',\n",
    "            'GRADES_PK_ASF','GRADES_KG_ASF','GRADES_4_ASF','GRADES_8_ASF','GRADES_12_ASF', 'GRADES_1_8_ASF', 'GRADES_9_12_ASF', 'GRADES_ALL_ASF',\n",
    "            'GRADES_PK_HIM','GRADES_KG_HIM','GRADES_4_HIM','GRADES_8_HIM','GRADES_12_HIM', 'GRADES_1_8_HIM', 'GRADES_9_12_HIM', 'GRADES_ALL_HIM',\n",
    "            'GRADES_PK_HIF','GRADES_KG_HIF','GRADES_4_HIF','GRADES_8_HIF','GRADES_12_HIF', 'GRADES_1_8_HIF', 'GRADES_9_12_HIF', 'GRADES_ALL_HIF',\n",
    "            'GRADES_PK_BLM','GRADES_KG_BLM','GRADES_4_BLM','GRADES_8_BLM','GRADES_12_BLM', 'GRADES_1_8_BLM', 'GRADES_9_12_BLM', 'GRADES_ALL_BLM',\n",
    "            'GRADES_PK_BLF','GRADES_KG_BLF','GRADES_4_BLF','GRADES_8_BLF','GRADES_12_BLF', 'GRADES_1_8_BLF', 'GRADES_9_12_BLF', 'GRADES_ALL_BLF',\n",
    "            'GRADES_PK_WHM','GRADES_KG_WHM','GRADES_4_WHM','GRADES_8_WHM','GRADES_12_WHM', 'GRADES_1_8_WHM', 'GRADES_9_12_WHM', 'GRADES_ALL_WHM',\n",
    "            'GRADES_PK_WHF','GRADES_KG_WHF','GRADES_4_WHF','GRADES_8_WHF','GRADES_12_WHF', 'GRADES_1_8_WHF', 'GRADES_9_12_WHF', 'GRADES_ALL_WHF',\n",
    "            'GRADES_PK_HPM','GRADES_KG_HPM','GRADES_4_HPM','GRADES_8_HPM','GRADES_12_HPM', 'GRADES_1_8_HPM', 'GRADES_9_12_HPM', 'GRADES_ALL_HPM',\n",
    "            'GRADES_PK_HPF','GRADES_KG_HPF','GRADES_4_HPF','GRADES_8_HPF','GRADES_12_HPF', 'GRADES_1_8_HPF', 'GRADES_9_12_HPF', 'GRADES_ALL_HPF',\n",
    "            'GRADES_PK_TRM','GRADES_KG_TRM','GRADES_4_TRM','GRADES_8_TRM','GRADES_12_TRM', 'GRADES_1_8_TRM', 'GRADES_9_12_TRM', 'GRADES_ALL_TRM',\n",
    "            'GRADES_PK_TRF','GRADES_KG_TRF','GRADES_4_TRF','GRADES_8_TRF','GRADES_12_TRF', 'GRADES_1_8_TRF', 'GRADES_9_12_TRF', 'GRADES_ALL_TRF']\n",
    "    X = X.drop(columns=drop)\n",
    "\n",
    "    #Filling missing scores with state average\n",
    "    X['AVG_READING_8_SCORE'] = X.groupby('STATE')['AVG_READING_8_SCORE'].transform(lambda x: x.fillna(x.mean()))\n",
    "    X['AVG_MATH_8_SCORE'] = X.groupby('STATE')['AVG_MATH_8_SCORE'].transform(lambda x: x.fillna(x.mean()))\n",
    "    X['AVG_READING_4_SCORE'] = X.groupby('STATE')['AVG_READING_4_SCORE'].transform(lambda x: x.fillna(x.mean()))\n",
    "    X['AVG_MATH_4_SCORE'] = X.groupby('STATE')['AVG_MATH_4_SCORE'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    #Adjusting revenue and expenditures to reflect inflation\n",
    "    #Revenue\n",
    "    X['ADJUSTED_TOTAL_REVENUE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'TOTAL_REVENUE'),axis=1)\n",
    "    X['ADJUSTED_FEDERAL_REVENUE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'FEDERAL_REVENUE'),axis=1)\n",
    "    X['ADJUSTED_STATE_REVENUE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'STATE_REVENUE'),axis=1)\n",
    "    X['ADJUSTED_LOCAL_REVENUE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'LOCAL_REVENUE'),axis=1)\n",
    "\n",
    "    #Expenditures\n",
    "    X['ADJUSTED_TOTAL_EXPENDITURE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'TOTAL_EXPENDITURE'),axis=1)\n",
    "    X['ADJUSTED_INSTRUCTION_EXPENDITURE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'INSTRUCTION_EXPENDITURE'),axis=1)\n",
    "    X['ADJUSTED_SUPPORT_SERVICES_EXPENDITURE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'SUPPORT_SERVICES_EXPENDITURE'),axis=1)\n",
    "    X['ADJUSTED_OTHER_EXPENDITURE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'OTHER_EXPENDITURE'),axis=1)\n",
    "    X['ADJUSTED_CAPITAL_OUTLAY_EXPENDITURE'] = X.apply(lambda row: inflation_adjustment(row,baseline_inflation, 'CAPITAL_OUTLAY_EXPENDITURE'),axis=1)\n",
    "    \n",
    "    #Calculating Percentages\n",
    "    #%of total revenue spent on education\n",
    "    X['%TOTAL_REVENUE'] = X['TOTAL_EXPENDITURE']/X['TOTAL_REVENUE']\n",
    "\n",
    "    #% of total expenditure spent on instruction\n",
    "    X['%TOTAL_EXPENDITURE_INSTRUCTION'] = X['INSTRUCTION_EXPENDITURE']/X['TOTAL_EXPENDITURE']\n",
    "    X['%TOTAL_EXPENDITURE_SUPPORT_SERVICES'] = X['SUPPORT_SERVICES_EXPENDITURE']/X['TOTAL_EXPENDITURE']\n",
    "    X['%TOTAL_EXPENDITURE_OTHER'] = X['OTHER_EXPENDITURE']/X['TOTAL_EXPENDITURE']\n",
    "    X['%TOTAL_EXPENDITURE_CAPITAL_OUTLAY'] = X['CAPITAL_OUTLAY_EXPENDITURE']/X['TOTAL_EXPENDITURE']\n",
    "    \n",
    "    #Cost per student\n",
    "    X['COST_PER_STUDENT'] = X['TOTAL_EXPENDITURE']/X['ENROLL']\n",
    "    \n",
    "    #Change year column to year\n",
    "    X['YEAR'] = pd.to_datetime(X['YEAR'], infer_datetime_format = True)\n",
    "    X['YEAR'] = X['YEAR'].dt.year\n",
    "    \n",
    "    #Return the wrangled dataframe\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 81), (171, 81), (102, 81))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test) \n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJUSTED_INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>ADJUSTED_SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>ADJUSTED_OTHER_EXPENDITURE</th>\n",
       "      <th>ADJUSTED_CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <th>%TOTAL_REVENUE</th>\n",
       "      <th>%TOTAL_EXPENDITURE_INSTRUCTION</th>\n",
       "      <th>%TOTAL_EXPENDITURE_SUPPORT_SERVICES</th>\n",
       "      <th>%TOTAL_EXPENDITURE_OTHER</th>\n",
       "      <th>%TOTAL_EXPENDITURE_CAPITAL_OUTLAY</th>\n",
       "      <th>COST_PER_STUDENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>1970</td>\n",
       "      <td>867035.0</td>\n",
       "      <td>10991081.0</td>\n",
       "      <td>1258519.0</td>\n",
       "      <td>4785070.0</td>\n",
       "      <td>4947492.0</td>\n",
       "      <td>10880480.0</td>\n",
       "      <td>5857285.0</td>\n",
       "      <td>3382519.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.979942e+06</td>\n",
       "      <td>4.030842e+06</td>\n",
       "      <td>5.640108e+05</td>\n",
       "      <td>7.731629e+05</td>\n",
       "      <td>0.989937</td>\n",
       "      <td>0.538330</td>\n",
       "      <td>0.310880</td>\n",
       "      <td>0.043499</td>\n",
       "      <td>0.059630</td>\n",
       "      <td>12.549067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>NEW_JERSEY</td>\n",
       "      <td>1970</td>\n",
       "      <td>1350330.0</td>\n",
       "      <td>19785039.0</td>\n",
       "      <td>797717.0</td>\n",
       "      <td>8135014.0</td>\n",
       "      <td>10852308.0</td>\n",
       "      <td>19812932.0</td>\n",
       "      <td>10169992.0</td>\n",
       "      <td>6429003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.413060e+07</td>\n",
       "      <td>8.932715e+06</td>\n",
       "      <td>9.410234e+05</td>\n",
       "      <td>2.259859e+06</td>\n",
       "      <td>1.001410</td>\n",
       "      <td>0.513301</td>\n",
       "      <td>0.324485</td>\n",
       "      <td>0.034183</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>14.672659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>RHODE_ISLAND</td>\n",
       "      <td>1970</td>\n",
       "      <td>139157.0</td>\n",
       "      <td>2212352.0</td>\n",
       "      <td>234111.0</td>\n",
       "      <td>768713.0</td>\n",
       "      <td>1209528.0</td>\n",
       "      <td>2198940.0</td>\n",
       "      <td>1260021.0</td>\n",
       "      <td>736651.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432091e+06</td>\n",
       "      <td>8.372491e+05</td>\n",
       "      <td>1.066322e+05</td>\n",
       "      <td>4.969729e+04</td>\n",
       "      <td>0.993938</td>\n",
       "      <td>0.573013</td>\n",
       "      <td>0.335003</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.019885</td>\n",
       "      <td>15.801864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>OHIO</td>\n",
       "      <td>1970</td>\n",
       "      <td>1803966.0</td>\n",
       "      <td>18018740.0</td>\n",
       "      <td>1097349.0</td>\n",
       "      <td>7844992.0</td>\n",
       "      <td>9076399.0</td>\n",
       "      <td>18760200.0</td>\n",
       "      <td>8958790.0</td>\n",
       "      <td>6097596.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244770e+07</td>\n",
       "      <td>8.472245e+06</td>\n",
       "      <td>1.112844e+06</td>\n",
       "      <td>3.229254e+06</td>\n",
       "      <td>1.041149</td>\n",
       "      <td>0.477542</td>\n",
       "      <td>0.325028</td>\n",
       "      <td>0.042693</td>\n",
       "      <td>0.123887</td>\n",
       "      <td>10.399420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>1970</td>\n",
       "      <td>431776.0</td>\n",
       "      <td>4131800.0</td>\n",
       "      <td>392009.0</td>\n",
       "      <td>2556472.0</td>\n",
       "      <td>1183319.0</td>\n",
       "      <td>4057443.0</td>\n",
       "      <td>2058538.0</td>\n",
       "      <td>1396907.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.259128e+06</td>\n",
       "      <td>1.533026e+06</td>\n",
       "      <td>1.830688e+05</td>\n",
       "      <td>2.438090e+05</td>\n",
       "      <td>0.982004</td>\n",
       "      <td>0.507349</td>\n",
       "      <td>0.344283</td>\n",
       "      <td>0.041113</td>\n",
       "      <td>0.054754</td>\n",
       "      <td>9.397102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATE  YEAR     ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "920      WISCONSIN  1970   867035.0     10991081.0        1258519.0   \n",
       "591     NEW_JERSEY  1970  1350330.0     19785039.0         797717.0   \n",
       "1013  RHODE_ISLAND  1970   139157.0      2212352.0         234111.0   \n",
       "596           OHIO  1970  1803966.0     18018740.0        1097349.0   \n",
       "1104        NEVADA  1970   431776.0      4131800.0         392009.0   \n",
       "\n",
       "      STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "920       4785070.0      4947492.0         10880480.0   \n",
       "591       8135014.0     10852308.0         19812932.0   \n",
       "1013       768713.0      1209528.0          2198940.0   \n",
       "596       7844992.0      9076399.0         18760200.0   \n",
       "1104      2556472.0      1183319.0          4057443.0   \n",
       "\n",
       "      INSTRUCTION_EXPENDITURE  SUPPORT_SERVICES_EXPENDITURE  ...  \\\n",
       "920                 5857285.0                     3382519.0  ...   \n",
       "591                10169992.0                     6429003.0  ...   \n",
       "1013                1260021.0                      736651.0  ...   \n",
       "596                 8958790.0                     6097596.0  ...   \n",
       "1104                2058538.0                     1396907.0  ...   \n",
       "\n",
       "      ADJUSTED_INSTRUCTION_EXPENDITURE  ADJUSTED_SUPPORT_SERVICES_EXPENDITURE  \\\n",
       "920                       6.979942e+06                           4.030842e+06   \n",
       "591                       1.413060e+07                           8.932715e+06   \n",
       "1013                      1.432091e+06                           8.372491e+05   \n",
       "596                       1.244770e+07                           8.472245e+06   \n",
       "1104                      2.259128e+06                           1.533026e+06   \n",
       "\n",
       "      ADJUSTED_OTHER_EXPENDITURE  ADJUSTED_CAPITAL_OUTLAY_EXPENDITURE  \\\n",
       "920                 5.640108e+05                         7.731629e+05   \n",
       "591                 9.410234e+05                         2.259859e+06   \n",
       "1013                1.066322e+05                         4.969729e+04   \n",
       "596                 1.112844e+06                         3.229254e+06   \n",
       "1104                1.830688e+05                         2.438090e+05   \n",
       "\n",
       "      %TOTAL_REVENUE  %TOTAL_EXPENDITURE_INSTRUCTION  \\\n",
       "920         0.989937                        0.538330   \n",
       "591         1.001410                        0.513301   \n",
       "1013        0.993938                        0.573013   \n",
       "596         1.041149                        0.477542   \n",
       "1104        0.982004                        0.507349   \n",
       "\n",
       "      %TOTAL_EXPENDITURE_SUPPORT_SERVICES  %TOTAL_EXPENDITURE_OTHER  \\\n",
       "920                              0.310880                  0.043499   \n",
       "591                              0.324485                  0.034183   \n",
       "1013                             0.335003                  0.042666   \n",
       "596                              0.325028                  0.042693   \n",
       "1104                             0.344283                  0.041113   \n",
       "\n",
       "      %TOTAL_EXPENDITURE_CAPITAL_OUTLAY  COST_PER_STUDENT  \n",
       "920                            0.059630         12.549067  \n",
       "591                            0.082090         14.672659  \n",
       "1013                           0.019885         15.801864  \n",
       "596                            0.123887         10.399420  \n",
       "1104                           0.054754          9.397102  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 50, 51)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.STATE.nunique(), val.STATE.nunique(), test.STATE.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Baseline***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.505976\n",
       "3.0    0.486056\n",
       "1.0    0.007968\n",
       "Name: READING_PROF_8, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['READING_PROF_8'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My baseline is ~50% for my majority class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Fit a Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "\n",
    "target = 'READING_PROF_8'\n",
    "X_train = train.drop(columns=[target,'AVG_READING_8_SCORE'])\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=[target,'AVG_READING_8_SCORE'])\n",
    "y_val = val[target]\n",
    "X_test = test.drop(columns=[target,'AVG_READING_8_SCORE'])\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***XGBOOST***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classifier\n",
    "xg1 = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names = True, cols = ['STATE']),\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(seed = 42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "#Hyperparameter optimization with RandomSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'simpleimputer__strategy': ['mean', 'median'],\n",
    "    'xgbclassifier__learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'xgbclassifier__n_estimators': randint(50, 500),\n",
    "    'xgbclassifier__max_depth': [5, 10, 15, 20], \n",
    "    'xgbclassifier__gamma':[0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "    'xgbclassifier__min_child_weight':[1, 3, 5, 7],\n",
    "    'xgbclassifier__colsample_bytree':[0.3, 0.4, 0.5 , 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed: 46.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed: 60.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 63.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 64.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 69.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed: 71.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed: 73.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 74.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed: 75.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed: 77.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed: 78.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 79.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3953 tasks      | elapsed: 80.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 81.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4224 tasks      | elapsed: 83.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4317 tasks      | elapsed: 84.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4410 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4505 tasks      | elapsed: 85.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 86.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4697 tasks      | elapsed: 87.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed: 88.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 89.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 89.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed: 89.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 s, sys: 1.18 s, total: 35.3 s\n",
      "Wall time: 1h 29min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('onehotencoder',\n",
       "                                              OneHotEncoder(cols=['STATE'],\n",
       "                                                            drop_invariant=False,\n",
       "                                                            handle_missing='value',\n",
       "                                                            handle_unknown='value',\n",
       "                                                            return_df=True,\n",
       "                                                            use_cat_names=True,\n",
       "                                                            verbose=0)),\n",
       "                                             ('ordinalencoder',\n",
       "                                              OrdinalEncoder(cols=None,\n",
       "                                                             drop_invariant=False,\n",
       "                                                             handle_missing='value',\n",
       "                                                             handle_unknown='value',\n",
       "                                                             map...\n",
       "                                                                 0.3, 0.4],\n",
       "                                        'xgbclassifier__learning_rate': [0.05,\n",
       "                                                                         0.1,\n",
       "                                                                         0.15,\n",
       "                                                                         0.2,\n",
       "                                                                         0.25,\n",
       "                                                                         0.3],\n",
       "                                        'xgbclassifier__max_depth': [5, 10, 15,\n",
       "                                                                     20],\n",
       "                                        'xgbclassifier__min_child_weight': [1,\n",
       "                                                                            3,\n",
       "                                                                            5,\n",
       "                                                                            7],\n",
       "                                        'xgbclassifier__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a1d591510>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    xg1,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 1000,\n",
    "    cv = 5,\n",
    "    scoring = 'accuracy',\n",
    "    verbose = 10,\n",
    "    return_train_score = True,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best H yperparameters: {'simpleimputer__strategy': 'median', 'xgbclassifier__colsample_bytree': 0.3, 'xgbclassifier__gamma': 0.4, 'xgbclassifier__learning_rate': 0.25, 'xgbclassifier__max_depth': 5, 'xgbclassifier__min_child_weight': 7, 'xgbclassifier__n_estimators': 495}\n",
      "Accuracy: 0.5735686274509805\n",
      "Best Estimator: Pipeline(memory=None,\n",
      "         steps=[('onehotencoder',\n",
      "                 OneHotEncoder(cols=['STATE'], drop_invariant=False,\n",
      "                               handle_missing='value', handle_unknown='value',\n",
      "                               return_df=True, use_cat_names=True, verbose=0)),\n",
      "                ('ordinalencoder',\n",
      "                 OrdinalEncoder(cols=[], drop_invariant=False,\n",
      "                                handle_missing='value', handle_unknown='value',\n",
      "                                mapping=[], return_df=True, verbose=0)),\n",
      "                ('simpleimputer',...\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bytree=0.3,\n",
      "                               gamma=0.4, learning_rate=0.25, max_delta_step=0,\n",
      "                               max_depth=5, min_child_weight=7, missing=None,\n",
      "                               n_estimators=495, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=42, silent=True, subsample=1))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best H yperparameters:', search.best_params_)\n",
    "print('Accuracy:', search.best_score_)\n",
    "print('Best Estimator:', search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['STATE'], drop_invariant=False,\n",
       "                               handle_missing='value', handle_unknown='value',\n",
       "                               return_df=True, use_cat_names=True, verbose=0)),\n",
       "                ('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=[], drop_invariant=False,\n",
       "                                handle_missing='value', handle_unknown='value',\n",
       "                                mapping=[], return_df=True, verbose=0)),\n",
       "                ('simpleimputer',...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=0.3,\n",
       "                               gamma=0.4, learning_rate=0.25, max_delta_step=0,\n",
       "                               max_depth=5, min_child_weight=7, missing=None,\n",
       "                               n_estimators=495, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=True, subsample=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg1 = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names = True, cols = ['STATE']),\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy = 'mean'),\n",
    "    XGBClassifier(colsample_bytree = 0.3, \n",
    "                 gamma = 0.4, \n",
    "                 learning_rate = 0.25, max_depth = 5, \n",
    "                 min_child_weight = 7, \n",
    "                 n_estimators = 495)\n",
    "    )\n",
    "\n",
    "#Fit on train, score on val\n",
    "xg1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9920318725099602\n",
      "Validation Accuracy 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Val accuracy\n",
    "print('Train Accuracy', xg1.score(X_train, y_train))\n",
    "print('Validation Accuracy', xg1.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['YEAR', 'ENROLL', 'TOTAL_REVENUE', 'FEDERAL_REVENUE',\n",
    "       'STATE_REVENUE', 'LOCAL_REVENUE', 'TOTAL_EXPENDITURE',\n",
    "       'INSTRUCTION_EXPENDITURE', 'SUPPORT_SERVICES_EXPENDITURE',\n",
    "       'OTHER_EXPENDITURE', 'CAPITAL_OUTLAY_EXPENDITURE','AVG_MATH_4_SCORE',\n",
    "       'AVG_READING_4_SCORE', 'AVG_MATH_8_SCORE', \n",
    "       'MATH_PROF_8', 'ADJUSTED_TOTAL_REVENUE',\n",
    "       'ADJUSTED_FEDERAL_REVENUE', 'ADJUSTED_STATE_REVENUE',\n",
    "       'ADJUSTED_LOCAL_REVENUE', 'ADJUSTED_TOTAL_EXPENDITURE',\n",
    "       'ADJUSTED_INSTRUCTION_EXPENDITURE',\n",
    "       'ADJUSTED_SUPPORT_SERVICES_EXPENDITURE', 'ADJUSTED_OTHER_EXPENDITURE',\n",
    "       'ADJUSTED_CAPITAL_OUTLAY_EXPENDITURE', '%TOTAL_REVENUE',\n",
    "       '%TOTAL_EXPENDITURE_INSTRUCTION', '%TOTAL_EXPENDITURE_SUPPORT_SERVICES',\n",
    "       '%TOTAL_EXPENDITURE_OTHER', '%TOTAL_EXPENDITURE_CAPITAL_OUTLAY',\n",
    "       'COST_PER_STUDENT']\n",
    "\n",
    "target = 'READING_PROF_8'\n",
    "X_train_new = train[features]\n",
    "y_train = train[target]\n",
    "X_val_new = val[features]\n",
    "y_val = val[target]\n",
    "X_test_new = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classifier\n",
    "xg2 = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(seed = 42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization with RandomSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'simpleimputer__strategy': ['mean', 'median'],\n",
    "    'xgbclassifier__learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'xgbclassifier__n_estimators': randint(50, 500),\n",
    "    'xgbclassifier__max_depth': [5, 10, 15, 20], \n",
    "    'xgbclassifier__gamma':[0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "    'xgbclassifier__min_child_weight':[1, 3, 5, 7],\n",
    "    'xgbclassifier__colsample_bytree':[0.3, 0.4, 0.5 , 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3953 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4224 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4317 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4410 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4505 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4697 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.5 s, sys: 898 ms, total: 26.4 s\n",
      "Wall time: 13min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('simpleimputer',\n",
       "                                              SimpleImputer(add_indicator=False,\n",
       "                                                            copy=True,\n",
       "                                                            fill_value=None,\n",
       "                                                            missing_values=nan,\n",
       "                                                            strategy='mean',\n",
       "                                                            verbose=0)),\n",
       "                                             ('xgbclassifier',\n",
       "                                              XGBClassifier(base_score=0.5,\n",
       "                                                            booster='gbtree',\n",
       "                                                            colsample_bylevel=1,\n",
       "                                                            colsample_bytree=1,\n",
       "                                                            gamma=0,\n",
       "                                                            learning_rate=0.1,\n",
       "                                                            max_delta_step=0,\n",
       "                                                            max...\n",
       "                                                                 0.3, 0.4],\n",
       "                                        'xgbclassifier__learning_rate': [0.05,\n",
       "                                                                         0.1,\n",
       "                                                                         0.15,\n",
       "                                                                         0.2,\n",
       "                                                                         0.25,\n",
       "                                                                         0.3],\n",
       "                                        'xgbclassifier__max_depth': [5, 10, 15,\n",
       "                                                                     20],\n",
       "                                        'xgbclassifier__min_child_weight': [1,\n",
       "                                                                            3,\n",
       "                                                                            5,\n",
       "                                                                            7],\n",
       "                                        'xgbclassifier__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a1d586790>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "search2 = RandomizedSearchCV(\n",
    "    xg2,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 1000,\n",
    "    cv = 5,\n",
    "    scoring = 'accuracy',\n",
    "    verbose = 10,\n",
    "    return_train_score = True,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "search2.fit(X_train_new, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best H yperparameters: {'simpleimputer__strategy': 'mean', 'xgbclassifier__colsample_bytree': 0.7, 'xgbclassifier__gamma': 0.4, 'xgbclassifier__learning_rate': 0.3, 'xgbclassifier__max_depth': 15, 'xgbclassifier__min_child_weight': 3, 'xgbclassifier__n_estimators': 122}\n",
      "Accuracy: 0.5653333333333334\n",
      "Best Estimator: Pipeline(memory=None,\n",
      "         steps=[('simpleimputer',\n",
      "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "                               missing_values=nan, strategy='mean',\n",
      "                               verbose=0)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bytree=0.7,\n",
      "                               gamma=0.4, learning_rate=0.3, max_delta_step=0,\n",
      "                               max_depth=15, min_child_weight=3, missing=None,\n",
      "                               n_estimators=122, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=42, silent=True, subsample=1))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best H yperparameters:', search2.best_params_)\n",
    "print('Accuracy:', search2.best_score_)\n",
    "print('Best Estimator:', search2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('simpleimputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=0.7,\n",
       "                               gamma=0.4, learning_rate=0.3, max_delta_step=0,\n",
       "                               max_depth=15, min_child_weight=3, missing=None,\n",
       "                               n_estimators=122, n_jobs=1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=True, subsample=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg2 = make_pipeline(\n",
    "    SimpleImputer(strategy = 'mean'),\n",
    "    XGBClassifier(colsample_bytree = 0.7, \n",
    "                gamma = 0.4, \n",
    "                learning_rate = 0.3, \n",
    "                max_depth =  15, \n",
    "                min_child_weight =  3, \n",
    "                n_estimators = 122)\n",
    ")\n",
    "\n",
    "#Fit on train, score on val\n",
    "xg2.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9960159362549801\n",
      "Validation Accuracy 0.52046783625731\n"
     ]
    }
   ],
   "source": [
    "# Val accuracy\n",
    "print('Train Accuracy', xg2.score(X_train_new, y_train))\n",
    "print('Validation Accuracy', xg2.score(X_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
